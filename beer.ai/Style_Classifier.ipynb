{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Classifier\n",
    "Let's predict style from ingredients.\n",
    "This notebook depends on: \n",
    "* `recipe_vecs.h5`, which is generated by `recipe2vec.py`\n",
    "* `all_recipes.h5`, which is generated by `converter.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('recipe_vecs.h5', 'r') as store:\n",
    "    recipe_vecs = store.get('vecs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('all_recipes.h5', 'r') as store:\n",
    "    recipe_catalog = store.get('core')\n",
    "    recipe_catalog = recipe_catalog.loc[recipe_vecs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data: pick a small number of styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american ipa                  30461\n",
       "american pale ale             24671\n",
       "specialty beer                11383\n",
       "imperial ipa                   7781\n",
       "american amber ale             5799\n",
       "saison                         5531\n",
       "american wheat or rye beer     4740\n",
       "american brown ale             4234\n",
       "robust porter                  3892\n",
       "blonde ale                     3700\n",
       "Name: style_name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_catalog.style_name.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_styles = ['american ipa', 'robust porter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_recipes = recipe_catalog.style_name.isin(selected_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recipe_catalog_select = recipe_catalog[selected_recipes].copy()\n",
    "#recipe_vecs_select = recipe_vecs[selected_recipes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy target variable: is_ipa\n",
    "* 1 if the style is American IPA\n",
    "* 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_catalog['is_ipa'] = (recipe_catalog.style_name == 'american ipa').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = recipe_catalog['is_ipa'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "             with_scaling=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(recipe_vecs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(recipe_vecs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.00000000e+01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.35217745e-01, 0.00000000e+00, 6.65373064e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Split arrays or matrices into random train and test subsets\n",
       "\n",
       "Quick utility that wraps input validation and\n",
       "``next(ShuffleSplit().split(X, y))`` and application to input data\n",
       "into a single call for splitting (and optionally subsampling) data in a\n",
       "oneliner.\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*arrays : sequence of indexables with same length / shape[0]\n",
       "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
       "    matrices or pandas dataframes.\n",
       "\n",
       "test_size : float, int or None, optional (default=None)\n",
       "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
       "    of the dataset to include in the test split. If int, represents the\n",
       "    absolute number of test samples. If None, the value is set to the\n",
       "    complement of the train size. If ``train_size`` is also None, it will\n",
       "    be set to 0.25.\n",
       "\n",
       "train_size : float, int, or None, (default=None)\n",
       "    If float, should be between 0.0 and 1.0 and represent the\n",
       "    proportion of the dataset to include in the train split. If\n",
       "    int, represents the absolute number of train samples. If None,\n",
       "    the value is automatically set to the complement of the test size.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional (default=None)\n",
       "    If int, random_state is the seed used by the random number generator;\n",
       "    If RandomState instance, random_state is the random number generator;\n",
       "    If None, the random number generator is the RandomState instance used\n",
       "    by `np.random`.\n",
       "\n",
       "shuffle : boolean, optional (default=True)\n",
       "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
       "    then stratify must be None.\n",
       "\n",
       "stratify : array-like or None (default=None)\n",
       "    If not None, data is split in a stratified fashion, using this as\n",
       "    the class labels.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "splitting : list, length=2 * len(arrays)\n",
       "    List containing train-test split of inputs.\n",
       "\n",
       "    .. versionadded:: 0.16\n",
       "        If the input is sparse, the output will be a\n",
       "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
       "        input type.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
       ">>> X\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])\n",
       ">>> list(y)\n",
       "[0, 1, 2, 3, 4]\n",
       "\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
       "...     X, y, test_size=0.33, random_state=42)\n",
       "...\n",
       ">>> X_train\n",
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])\n",
       ">>> y_train\n",
       "[2, 0, 3]\n",
       ">>> X_test\n",
       "array([[2, 3],\n",
       "       [8, 9]])\n",
       ">>> y_test\n",
       "[1, 4]\n",
       "\n",
       ">>> train_test_split(y, shuffle=False)\n",
       "[[0, 1, 2], [3, 4]]\n",
       "\u001b[0;31mFile:\u001b[0m      ~/code_home/beer.ai/env/lib/python3.8/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rwelch/code_home/beer.ai/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213395457192778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode categorical labels: style categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_values = le.fit_transform(recipe_catalog_select.style_name.values)\n",
    "encoded_values = encoded_values.reshape(len(encoded_values), 1)\n",
    "encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34353x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34353 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_labels = ohe.fit_transform(encoded_values)\n",
    "ohe_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale inputs, fit to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "             with_scaling=True)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(recipe_vecs_select.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.70238095e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.16415889e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [6.64408860e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.87742032e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.00000000e+01],\n",
       "       [1.77557540e+00, 0.00000000e+00, 6.65373064e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = scaler.transform(recipe_vecs_select.values)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ohe_labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-207.1271140806192"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.5494817161023"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beer-env",
   "language": "python",
   "name": "beer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
